# MVP Spec (Phase 1)

Phase 1 focuses on **news monitoring only**. Court record scraping is deferred to Phase 2.

Scan Israeli news websites for enforcement-related stories, deduplicate across sources, present in unified format.

---

## What to Look For

### Primary Topics
- **Brothel raids/closures** - police operations shutting down locations
- **Prostitution arrests** - individuals caught in prostitution-related offenses
- **Pimp arrests** - ×¡×¨×¡×•×¨×™× caught, charged, or sentenced
- **Human trafficking** - ×¡×—×¨ ×‘×‘× ×™ ××“× cases and arrests
- **Closure orders** - ×¦×•×•×™ ×¡×’×™×¨×” issued against locations

### Secondary Topics
- **Massage parlor/spa busts** - often fronts for prostitution
- **Online platform takedowns** - escort sites, ads platforms
- **Police operations** - ××‘×¦×¢×™ ××©×˜×¨×” targeting prostitution rings
- **Court sentences** - verdicts and sentencing in related cases
- **Administrative fines** - ×§× ×¡×•×ª for prostitution consumption
- **Location exposÃ©s** - reports identifying active prostitution areas
- **Trafficking victim rescues** - ×—×™×œ×•×¥ × ×¤×’×¢×•×ª ×¡×—×¨

---

## News Sources

MVP uses a hybrid approach: **2 RSS sources + 2 scraped sources**.

### RSS Sources (simpler, more reliable)

| Source | RSS URL | Notes |
|--------|---------|-------|
| Ynet | `ynet.co.il/Integration/StoryRss2.xml` | General news feed |
| Walla | `rss.walla.co.il/feed/1` | News feed |

### Scraped Sources (search results pages)

| Source | Search URL Pattern | Notes |
|--------|-------------------|-------|
| Mako | `mako.co.il/AjaxPage?...&q={query}` | Men section has relevant content |
| Maariv | `maariv.co.il/news/law` + search | Law/crime section |

### Strategy

1. **RSS**: Fetch feed, filter items by date (last X days), pre-filter by keywords
2. **Scraping**: Search with Hebrew keywords, parse results, filter by date
3. Respect rate limits: 1-2 second delays between requests

### Example Articles (for validation)

See [articles_examples.md](./articles_examples.md) for real examples found in the last 2 weeks. The system should detect these types of articles:
- Mako "men" section crime reports
- Maariv law/crime section
- Cross-published stories (same story on multiple sites)

---

## Core Abstractions

```
Config           - YAML: sources list, keywords, days back, notifier settings
Source           - Protocol: fetch(days) -> list[RawArticle]
  â”œâ”€ RSSSource   - Fetch RSS feed, filter by keywords + date
  â””â”€ Scraper     - Search with keywords, parse HTML, filter by date
RawArticle       - url, title, snippet, date, source_name
Classifier       - LLM: is_relevant(article) -> bool, category, sub_category
Deduplicator     - Group same story across sources by similarity
UnifiedItem      - Canonical representation: headline, summary, sources[], date, category, sub_category
Notifier         - Protocol: send(items) -> None
```

---

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RSS Sources  â”‚     â”‚  Scrapers    â”‚
â”‚ (Ynet,Walla) â”‚     â”‚ (Mako,Maariv)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ feedparser         â”‚ beautifulsoup
       â”‚ + keyword filter   â”‚ + date filter
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Raw Articles â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Classifier  â”‚ (LLM: relevant? category? sub_category?)
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Deduplicator â”‚ (group same story across sources)
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Renderer   â”‚ â†’ CLI or Telegram
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **RSS sources**: Fetch feed â†’ filter by keywords â†’ filter by date
2. **Scrapers**: Search with keywords â†’ parse HTML â†’ filter by date
3. Combine all raw articles
4. Filter out already-seen URLs
5. Classify with LLM (relevance + category + sub_category)
6. Deduplicate: group articles about same story
7. Render unified items with all source links
8. Output to CLI or Telegram

---

## MVP Scope

### In Scope
- **4 news sources**: 2 via RSS (Ynet, Walla) + 2 via scraping (Mako, Maariv)
- **Configurable time window**: scan last X days (e.g., 7 or 14 days)
- **Hybrid fetching**: RSS feeds + search page scraping
- **CLI output**: `denbust scan` prints unified items
- **Telegram notifications**: optional, for new items
- **LLM classification**: relevance + category + sub_category
- **Cross-source deduplication**: same story = one item with multiple source links
- **Simple persistence**: track seen URLs to avoid re-alerting
- **Validation**: should find articles like those in articles_examples.md

### Out of Scope (Phase 1)
- Court records scraping (Phase 2)
- Full article text extraction (search snippets sufficient)
- Historical database / analytics
- Web dashboard
- Email notifications
- Scheduled daemon (use cron for now)

---

## Tech Stack

| Layer | Choice | Why |
|-------|--------|-----|
| Language | Python 3.11+ | Type hints, async |
| HTTP | `httpx` | Async, timeouts, retries |
| RSS | `feedparser` | Standard RSS parsing |
| HTML Parsing | `beautifulsoup4` + `lxml` | Robust scraping |
| Config | `pydantic` + `pyyaml` | Validation |
| CLI | `typer` | Simple, typed |
| LLM | `anthropic` (Claude) | Good Hebrew support |
| Dedup | `difflib` | Title similarity scoring |
| Persistence | JSON file | Simple seen-URLs tracking |
| Telegram | `httpx` direct | Lightweight |
| Testing | `pytest` + `respx` | Mock HTTP |
| Lint | `ruff` | Fast |

---

## File Structure

```
denbust/
â”œâ”€â”€ src/denbust/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py              # typer CLI
â”‚   â”œâ”€â”€ config.py           # Config models
â”‚   â”œâ”€â”€ models.py           # RawArticle, UnifiedItem
â”‚   â”œâ”€â”€ pipeline.py         # Orchestration
â”‚   â”œâ”€â”€ sources/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py         # Source protocol
â”‚   â”‚   â”œâ”€â”€ rss.py          # Generic RSS fetcher (Ynet, Walla)
â”‚   â”‚   â”œâ”€â”€ mako.py         # Mako scraper
â”‚   â”‚   â””â”€â”€ maariv.py       # Maariv scraper
â”‚   â”œâ”€â”€ classifier/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ relevance.py    # LLM classification
â”‚   â”œâ”€â”€ dedup/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ similarity.py   # Cross-source deduplication
â”‚   â”œâ”€â”€ output/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ formatter.py    # Unified item rendering
â”‚   â”‚   â””â”€â”€ telegram.py     # Telegram notifier
â”‚   â””â”€â”€ store/
â”‚       â””â”€â”€ seen.py         # Track seen URLs (JSON)
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ rss/            # Sample RSS XML
â”‚       â””â”€â”€ html/           # Sample search result HTML
â”œâ”€â”€ data/
â”‚   â””â”€â”€ seen.json           # Persisted seen URLs
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ news.yaml           # Default config
â””â”€â”€ pyproject.toml
```

---

## Example Config

```yaml
# agents/news.yaml
name: enforcement-news
days: 14  # How many days back to search

sources:
  # RSS sources - filter by keywords after fetching
  - name: ynet
    type: rss
    url: https://www.ynet.co.il/Integration/StoryRss2.xml
    enabled: true

  - name: walla
    type: rss
    url: https://rss.walla.co.il/feed/1
    enabled: true

  # Scraped sources - search with keywords
  - name: mako
    type: scraper
    enabled: true

  - name: maariv
    type: scraper
    enabled: true

keywords:  # For RSS filtering and scraper searches
  - ×–× ×•×ª
  - ×‘×™×ª ×‘×•×©×ª
  - ×¡×¨×¡×•×¨
  - ×¡×—×¨ ×‘×‘× ×™ ××“×
  - ×¦×• ×¡×’×™×¨×”
  - ×œ×™×•×•×™
  - × ×¢×¨×•×ª ×œ×™×•×•×™
  - ×ª×¢×©×™×™×ª ×”××™×Ÿ
  - ×¢×™×¡×•×™ ×—×©×•×“
  - ×–×™×¨×ª ×–× ×•×ª

classifier:
  provider: anthropic
  model: claude-sonnet-4-20250514
  # ANTHROPIC_API_KEY from env

dedup:
  similarity_threshold: 0.7  # Title similarity for grouping

output:
  format: cli  # or 'telegram'
  # DENBUST_TELEGRAM_BOT_TOKEN, DENBUST_TELEGRAM_CHAT_ID from env

store:
  path: data/seen.json
```

---

## Categories & Sub-categories

Classification uses a two-level system: **category** + **sub-category**.

| Category | Sub-category | Description |
|----------|--------------|-------------|
| `brothel` | `closure` | Raid, shutdown, closure order issued |
| `brothel` | `opening` | Reopening, still operating despite order, new location discovered |
| `prostitution` | `arrest` | Individual arrested for prostitution-related offense |
| `prostitution` | `fine` | Administrative fine issued |
| `pimping` | `arrest` | Pimp arrested |
| `pimping` | `sentence` | Pimp sentenced/convicted |
| `trafficking` | `arrest` | Trafficking suspect arrested |
| `trafficking` | `rescue` | Victims rescued |
| `trafficking` | `sentence` | Trafficker sentenced |
| `enforcement` | `operation` | Police operation, general enforcement activity |
| `enforcement` | `other` | Other enforcement-related news |

The `brothel.opening` sub-category is particularly important - it indicates potential enforcement gaps where places continue operating.

---

## Classification Prompt (Draft)

```
You classify Hebrew news articles for relevance to anti-prostitution enforcement.

Given a news headline and snippet, determine:
1. Is this relevant to: brothels, prostitution, pimping, human trafficking, or enforcement?
2. Category: brothel | prostitution | pimping | trafficking | enforcement | not_relevant
3. Sub-category (if relevant):
   - brothel: closure | opening
   - prostitution: arrest | fine
   - pimping: arrest | sentence
   - trafficking: arrest | rescue | sentence
   - enforcement: operation | other
4. Confidence: high | medium | low

Article:
×›×•×ª×¨×ª: {title}
×ª×§×¦×™×¨: {snippet}

Respond JSON only:
{"relevant": true/false, "category": "...", "sub_category": "...", "confidence": "..."}
```

---

## Unified Item Format (Output)

```
ğŸš¨ ×¤×©×™×˜×” ×¢×œ ×‘×™×ª ×‘×•×©×ª ×‘×¨××ª ×’×Ÿ
×ª××¨×™×š: 2026-02-15
×§×˜×’×•×¨×™×”: ×‘×™×ª ×‘×•×©×ª Â» ×¡×’×™×¨×”

×ª×§×¦×™×¨: ×”××©×˜×¨×” ×¤×©×˜×” ×¢×œ ×“×™×¨×” ×‘×¨××ª ×’×Ÿ ×©×¤×¢×œ×” ×›×‘×™×ª ×‘×•×©×ª. × ×¢×¦×¨×• 3 ×—×©×•×“×™×...

××§×•×¨×•×ª:
â€¢ Ynet: https://ynet.co.il/...
â€¢ Mako: https://mako.co.il/...
â€¢ Walla: https://walla.co.il/...
```

Category icons:
- ğŸš¨ brothel.closure (raid/shutdown)
- âš ï¸ brothel.opening (still operating / reopened)
- ğŸ‘® arrest (prostitution/pimping/trafficking)
- âš–ï¸ sentence
- ğŸ†˜ trafficking.rescue
- ğŸ” enforcement.operation

---

## Environment Variables

```bash
ANTHROPIC_API_KEY=sk-ant-...
DENBUST_TELEGRAM_BOT_TOKEN=123456:ABC...  # Optional
DENBUST_TELEGRAM_CHAT_ID=123456789        # Optional
```

---

## Done When

- [ ] `denbust scan` fetches from 4 sources (2 RSS + 2 scrapers)
- [ ] `--days` flag controls how far back to search (default from config)
- [ ] RSS sources: fetch feed, filter by keywords + date
- [ ] Scrapers: search with keywords, filter by date
- [ ] LLM classifies relevance + category + sub_category
- [ ] Same story from multiple sources = single unified item
- [ ] Unified items printed to CLI in readable Hebrew format
- [ ] Optional: Telegram notification for new items
- [ ] seen.json tracks URLs to avoid duplicate alerts on re-run
- [ ] **Validation**: system finds articles like those in articles_examples.md
- [ ] Unit tests for RSS parsing, HTML scraping, dedup logic
- [ ] Integration test with mocked responses

---

## Phase 2 Preview (Not in MVP)

- Israeli Courts website scraping
- Correlation: news story â†’ court case
- Location extraction and mapping
- Historical enforcement database
- Web dashboard with statistics
